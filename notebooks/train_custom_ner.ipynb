{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER model training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom parameters\n",
    "\n",
    "Customize your model training changing the default parameters:\n",
    "\n",
    "- __Pipeline settings__\n",
    "  - __verbose__: Boolean, print steps and partial results\n",
    "  - __p_seed__: Integer, used for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "verbose = True\n",
    "p_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Training set__\n",
    "  - __train_path__: String, path to annotated CSV\n",
    "  - __num_samples__: Integer\n",
    "  - __split_train__: Float, must be 0 < n < 1 . For example, 0.7 means 70% used for training the model.\n",
    "  - __split_validation__: Float, using the rest from split_train, keep portion for inference. For example, 0.1 means 10% used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data set parameters\n",
    "p_ner_vendor = True\n",
    "p_ner_product = True\n",
    "p_ner_version = True\n",
    "\n",
    "train_path = \"../datasets/trainsets/train_cpener_vpv_20k_wgh42.csv.gz\"\n",
    "num_samples = 5000\n",
    "split_train = 0.5\n",
    "split_validation = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Model settings__\n",
    "  - __pretrained_token_name__: \"Neurona/cpener-test\" # distilbert-base-uncased, distilbert-base-cased, bert-base-NER, bert-large-NER, flair/ner-english-ontonotes-fast, Neurona/cpener-test\n",
    "  - __pretrained_model_name__: \"Neurona/cpener-test\" # distilbert-base-uncased, distilbert-base-cased, bert-base-NER, bert-large-NER, flair/ner-english-ontonotes-fast, Neurona/cpener-test\n",
    "  - __num_epochs__: 10\n",
    "  - __num_decay__: 0.01\n",
    "  - __token_truncation__: False\n",
    "  - __train_learning_rate__: 2e-5\n",
    "  - __train_patience__: 8\n",
    "  - __train_batch_size__: 32\n",
    "  - __eval_batch_size__: 32\n",
    "  - __train_logging_steps__: 100\n",
    "  - __save_model_name__: \"cpener_vpv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "pretrained_token_name = \"distilbert-base-uncased\" # distilbert-base-uncased, distilbert-base-cased, bert-base-NER, bert-large-NER, flair/ner-english-ontonotes-fast, Neurona/cpener-test\n",
    "pretrained_model_name = \"distilbert-base-uncased\" # distilbert-base-uncased, distilbert-base-cased, bert-base-NER, bert-large-NER, flair/ner-english-ontonotes-fast, Neurona/cpener-test\n",
    "num_epochs = 50\n",
    "num_decay = 0.01\n",
    "token_truncation = False\n",
    "train_learning_rate = 2e-5\n",
    "train_patience = 5\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "train_logging_steps = 100\n",
    "save_model_path = \"../models\"\n",
    "\n",
    "# Inference validation\n",
    "results_path = \"../datasets/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/results/ner_predictions_vpv.csv'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (p_ner_vendor and p_ner_product and p_ner_version):\n",
    "    str_ner = \"vpv\"\n",
    "elif (p_ner_vendor and p_ner_product and not (p_ner_version)):\n",
    "    str_ner = \"vp\"\n",
    "elif (not (p_ner_vendor) and p_ner_product and p_ner_version):\n",
    "    str_ner = \"pv\"\n",
    "elif (p_ner_vendor and not (p_ner_product) and p_ner_version):\n",
    "    str_ner = \"vv\"\n",
    "elif (p_ner_vendor and not (p_ner_product) and not (p_ner_version)):\n",
    "    str_ner = \"vend\"\n",
    "elif (not (p_ner_vendor) and p_ner_product and not (p_ner_version)):\n",
    "    str_ner = \"prod\"\n",
    "elif (not (p_ner_vendor) and (not p_ner_product) and p_ner_version):\n",
    "    str_ner = \"vers\"\n",
    "else:\n",
    "    str_ner = \"nan\"\n",
    "\n",
    "results_path = f\"{results_path}/ner_predictions_{str_ner}.csv\"\n",
    "results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/db_cpener_vpv'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_name = f\"{save_model_path}/db_cpener_{str_ner}\"\n",
    "save_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Model\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import pipeline\n",
    "\n",
    "# Inference\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import Dataset\n",
    "\n",
    "# Set Seed\n",
    "np.random.seed(p_seed)\n",
    "\n",
    "# Set Start Time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_with_entities(raw_text: str):\n",
    "    # split the text by spaces only if the space does not occur between square brackets\n",
    "    # we do not want to split \"multi-word\" entity value yet\n",
    "    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", raw_text)\n",
    "\n",
    "    # a regex for matching the annotation according to our notation [entity_value](entity_name)\n",
    "    entity_value_pattern = r\"\\[(?P<value>.+?)\\]\\((?P<entity>.+?)\\)\"\n",
    "    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M)\n",
    "\n",
    "    tokens_with_entities = []\n",
    "\n",
    "    for raw_token in raw_tokens:\n",
    "        match = entity_value_pattern_compiled.match(raw_token)\n",
    "        if match:\n",
    "            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\")\n",
    "\n",
    "            # we prefix the name of entity differently\n",
    "            # B- indicates beginning of an entity\n",
    "            # I- indicates the token is not a new entity itself but rather a part of existing one\n",
    "            for i, raw_entity_token in enumerate(re.split(\"\\s\", raw_entity_value)):\n",
    "                entity_prefix = \"B\" if i == 0 else \"I\"\n",
    "                entity_name = f\"{entity_prefix}-{raw_entity_name}\"\n",
    "                tokens_with_entities.append((raw_entity_token, entity_name))\n",
    "        else:\n",
    "            tokens_with_entities.append((raw_token, \"O\"))\n",
    "\n",
    "    return tokens_with_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ner_out(out, ent_vend, ent_prod, ent_vers):\n",
    "    if (ent_vend):\n",
    "        ner_vendor = \"\"\n",
    "        scr_vendor = 0.0\n",
    "\n",
    "    if (ent_prod):\n",
    "        ner_product = \"\"\n",
    "        scr_product = 0.0\n",
    "\n",
    "    if (ent_vers):\n",
    "        ner_version = \"\"\n",
    "        scr_version = 0.0\n",
    "\n",
    "    if (out == []):\n",
    "        if (ent_vend and ent_prod and ent_vers):\n",
    "            return({\"ner_vendor\": ner_vendor,\n",
    "                    \"scr_vendor\": scr_vendor,\n",
    "                    \"ner_product\": ner_product,\n",
    "                    \"scr_product\": scr_product,\n",
    "                    \"ner_version\": ner_version,\n",
    "                    \"scr_version\": scr_version})\n",
    "        elif (ent_vend and ent_prod and not(ent_vers)):\n",
    "            return({\"ner_vendor\": ner_vendor,\n",
    "                    \"scr_vendor\": scr_vendor,\n",
    "                    \"ner_product\": ner_product,\n",
    "                    \"scr_product\": scr_product})\n",
    "        elif (not(ent_vend) and ent_prod and ent_vers):\n",
    "            return({\"ner_product\": ner_product,\n",
    "                    \"scr_product\": scr_product,\n",
    "                    \"ner_version\": ner_version,\n",
    "                    \"scr_version\": scr_version})\n",
    "        elif (ent_vend and not(ent_prod) and ent_vers):\n",
    "            return({\"ner_vendor\": ner_vendor,\n",
    "                    \"scr_vendor\": scr_vendor,\n",
    "                    \"ner_version\": ner_version,\n",
    "                    \"scr_version\": scr_version})\n",
    "        elif (ent_vend and not(ent_prod) and not(ent_vers)):\n",
    "            return({\"ner_vendor\": ner_vendor,\n",
    "                    \"scr_vendor\": scr_vendor})\n",
    "        elif (not(ent_vend) and ent_prod and not(ent_vers)):\n",
    "            return({\"ner_product\": ner_product,\n",
    "                    \"scr_product\": scr_product})\n",
    "        elif (not(ent_vend) and not(ent_prod) and ent_vers):\n",
    "            return({\"ner_version\": ner_version,\n",
    "                    \"scr_version\": scr_version})\n",
    "        else:\n",
    "            return({})\n",
    "    \n",
    "    df_ner = pd.DataFrame.from_dict(out)  \n",
    "    \n",
    "    if ('vendor' in df_ner['entity_group'].values):\n",
    "        ner_vendor = df_ner[df_ner['entity_group'] == \"vendor\"].groupby(\"entity_group\").agg({'word': ' '.join}).word.iloc[0]\n",
    "        ner_vendor = re.sub(r'([^ ]+) ([^\\d|^\\w]) ([^ ]+)', \"\\\\1\\\\2\\\\3\", ner_vendor)\n",
    "        scr_vendor = df_ner[df_ner['entity_group'] == \"vendor\"].groupby(\"entity_group\").mean(\"score\").score.iloc[0]\n",
    "    if ('product' in df_ner['entity_group'].values):\n",
    "        ner_product = df_ner[df_ner['entity_group'] == \"product\"] .groupby(\"entity_group\").agg({'word': ' '.join}).word.iloc[0]\n",
    "        ner_product = re.sub(r'([^ ]+) ([^\\d|^\\w]) ([^ ]+)', \"\\\\1\\\\2\\\\3\", ner_product)\n",
    "        scr_product = df_ner[df_ner['entity_group'] == \"product\"] .groupby(\"entity_group\").mean(\"score\").score.iloc[0]\n",
    "    if ('version' in df_ner['entity_group'].values):\n",
    "        ner_version = df_ner[df_ner['entity_group'] == \"version\"] .groupby(\"entity_group\").agg({'word': '.'.join}).word.iloc[0]\n",
    "        ner_version = re.sub(r'\\.+', \".\", ner_version)\n",
    "        scr_version = df_ner[df_ner['entity_group'] == \"version\"] .groupby(\"entity_group\").mean(\"score\").score.iloc[0]\n",
    "    \n",
    "    if (ent_vend and ent_prod and ent_vers):\n",
    "        return({\"ner_vendor\": ner_vendor,\n",
    "                \"scr_vendor\": scr_vendor,\n",
    "                \"ner_product\": ner_product,\n",
    "                \"scr_product\": scr_product,\n",
    "                \"ner_version\": ner_version,\n",
    "                \"scr_version\": scr_version})\n",
    "    elif (ent_vend and ent_prod and not(ent_vers)):\n",
    "        return({\"ner_vendor\": ner_vendor,\n",
    "                \"scr_vendor\": scr_vendor,\n",
    "                \"ner_product\": ner_product,\n",
    "                \"scr_product\": scr_product})\n",
    "    elif (not(ent_vend) and ent_prod and ent_vers):\n",
    "        return({\"ner_product\": ner_product,\n",
    "                \"scr_product\": scr_product,\n",
    "                \"ner_version\": ner_version,\n",
    "                \"scr_version\": scr_version})\n",
    "    elif (ent_vend and not(ent_prod) and ent_vers):\n",
    "        return({\"ner_vendor\": ner_vendor,\n",
    "                \"scr_vendor\": scr_vendor,\n",
    "                \"ner_version\": ner_version,\n",
    "                \"scr_version\": scr_version})\n",
    "    elif (ent_vend and not(ent_prod) and not(ent_vers)):\n",
    "        return({\"ner_vendor\": ner_vendor,\n",
    "                \"scr_vendor\": scr_vendor})\n",
    "    elif (not(ent_vend) and ent_prod and not(ent_vers)):\n",
    "        return({\"ner_product\": ner_product,\n",
    "                \"scr_product\": scr_product})\n",
    "    elif (not(ent_vend) and not(ent_prod) and ent_vers):\n",
    "        return({\"ner_version\": ner_version,\n",
    "                \"scr_version\": scr_version})\n",
    "    else:\n",
    "        return({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hackvers(row):\n",
    "    vers = [i for i in row['title'].split() if i.startswith(row['ner_version'])]\n",
    "    return ''.join(vers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Class for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataMaker:\n",
    "    def __init__(self, texts):\n",
    "        self.unique_entities = []\n",
    "        self.processed_texts = []\n",
    "\n",
    "        temp_processed_texts = []\n",
    "        for text in texts:\n",
    "            tokens_with_entities = get_tokens_with_entities(text)\n",
    "            for _, ent in tokens_with_entities:\n",
    "                if ent not in self.unique_entities:\n",
    "                    self.unique_entities.append(ent)\n",
    "            temp_processed_texts.append(tokens_with_entities)\n",
    "\n",
    "        self.unique_entities.sort(key=lambda ent: ent if ent != \"O\" else \"\")\n",
    "\n",
    "        for tokens_with_entities in temp_processed_texts:\n",
    "            self.processed_texts.append([(t, self.unique_entities.index(ent)) for t, ent in tokens_with_entities])\n",
    "\n",
    "    @property\n",
    "    def id2label(self):\n",
    "        return dict(enumerate(self.unique_entities))\n",
    "\n",
    "    @property\n",
    "    def label2id(self):\n",
    "        return {v:k for k, v in self.id2label.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def _process_tokens_for_one_text(id, tokens_with_encoded_entities):\n",
    "            ner_tags = []\n",
    "            tokens = []\n",
    "            for t, ent in tokens_with_encoded_entities:\n",
    "                ner_tags.append(ent)\n",
    "                tokens.append(t)\n",
    "\n",
    "            return {\n",
    "                \"id\": id,\n",
    "                \"ner_tags\": ner_tags,\n",
    "                \"tokens\": tokens\n",
    "            }\n",
    "\n",
    "        tokens_with_encoded_entities = self.processed_texts[idx]\n",
    "        if isinstance(idx, int):\n",
    "            return _process_tokens_for_one_text(idx, tokens_with_encoded_entities)\n",
    "        else:\n",
    "            return [_process_tokens_for_one_text(i+idx.start, tee) for i, tee in enumerate(tokens_with_encoded_entities)]\n",
    "\n",
    "    def as_hf_dataset(self, tokenizer):\n",
    "        from datasets import Dataset, Features, Value, ClassLabel, Sequence\n",
    "        def tokenize_and_align_labels(examples):\n",
    "            tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=token_truncation, is_split_into_words=True)\n",
    "\n",
    "            labels = []\n",
    "            for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "                word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "                previous_word_idx = None\n",
    "                label_ids = []\n",
    "                for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "                    if word_idx is None:\n",
    "                        label_ids.append(-100)\n",
    "                    elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                        label_ids.append(label[word_idx])\n",
    "                    else:\n",
    "                        label_ids.append(-100)\n",
    "                    previous_word_idx = word_idx\n",
    "                labels.append(label_ids)\n",
    "\n",
    "            tokenized_inputs[\"labels\"] = labels\n",
    "            return tokenized_inputs\n",
    "\n",
    "        ids, ner_tags, tokens = [], [], []\n",
    "        for i, pt in enumerate(self.processed_texts):\n",
    "            ids.append(i)\n",
    "            pt_tokens,pt_tags = list(zip(*pt))\n",
    "            ner_tags.append(pt_tags)\n",
    "            tokens.append(pt_tokens)\n",
    "        data = {\n",
    "            \"id\": ids,\n",
    "            \"ner_tags\": ner_tags,\n",
    "            \"tokens\": tokens\n",
    "        }\n",
    "        features = Features({\n",
    "            \"tokens\": Sequence(Value(\"string\")),\n",
    "            \"ner_tags\": Sequence(ClassLabel(names=dm.unique_entities)),\n",
    "            \"id\": Value(\"int32\")\n",
    "        })\n",
    "        ds = Dataset.from_dict(data, features)\n",
    "        tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n",
    "        return tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load annotated data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read without chunks:  0.6157352924346924 seconds\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_path)\n",
    "df['annotated'] = df['annotated'].astype(str) + '.'\n",
    "\n",
    "if (verbose):\n",
    "    # time taken to read data\n",
    "    e_time = time.time()\n",
    "    print(\"Read without chunks: \", (e_time-start_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select custom sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.loc[np.random.choice(df.index, num_samples)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into Train, Test and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, validate, test = train_validate_test_split(df_sample, train_percent=split_train, \n",
    "                                                  validate_percent=split_validation, seed=p_seed)\n",
    "\n",
    "train_text = train.annotated.to_list()\n",
    "test_text = test.annotated.to_list()\n",
    "validate_text = validate.annotated.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train annotated sample: [('node-postgres', 'B-vendor'), ('pg', 'B-product'), ('0.5.7', 'B-version'), ('for', 'O'), ('node.js.', 'O')]\n",
      "Test annotated sample: [('nbdkit', 'B-vendor'), ('project', 'I-vendor'), ('nbdkit', 'B-product'), ('1.2.6', 'B-version')]\n",
      "Validation annotated sample: [('10web', 'B-vendor'), ('form', 'B-product'), ('maker', 'I-product'), ('1.8.0', 'B-version'), ('for', 'O'), ('wordpress.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "if (verbose):\n",
    "    print(\"Train annotated sample: \" + str(get_tokens_with_entities(train_text[0])))\n",
    "    print(\"Test annotated sample: \" + str(get_tokens_with_entities(test_text[0])))\n",
    "    print(\"Validation annotated sample: \" + str(get_tokens_with_entities(validate_text[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NER Data Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN NER DATA OBJECTS\n",
      "  - total examples = 2500\n",
      "  - labels = {0: 'O', 1: 'B-product', 2: 'B-vendor', 3: 'B-version', 4: 'I-product', 5: 'I-vendor'}\n",
      "  - Examples = [{'id': 0, 'ner_tags': [2, 1, 3, 0, 0], 'tokens': ['node-postgres', 'pg', '0.5.7', 'for', 'node.js.']}, {'id': 1, 'ner_tags': [2, 1, 3, 0, 0, 0], 'tokens': ['call-cc', 'chicken', '5.3.0', 'release', 'candidate', '2.']}, {'id': 2, 'ner_tags': [2, 5, 1, 3], 'tokens': ['udev', 'project', 'udev', '080']}]\n"
     ]
    }
   ],
   "source": [
    "# Create Training NER Data Object\n",
    "dm = NERDataMaker(train_text)\n",
    "if (verbose):\n",
    "    print(\"TRAIN NER DATA OBJECTS\")\n",
    "    print(f\"  - total examples = {len(dm)}\")\n",
    "    print(f\"  - labels = {dm.id2label}\")\n",
    "    print(f\"  - Examples = {dm[0:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST NER DATA OBJECTS\n",
      "  - total examples = 2000\n",
      "  - labels = {0: 'O', 1: 'B-product', 2: 'B-vendor', 3: 'B-version', 4: 'I-product', 5: 'I-vendor'}\n",
      "  - Examples = [{'id': 0, 'ner_tags': [2, 5, 1, 3], 'tokens': ['nbdkit', 'project', 'nbdkit', '1.2.6']}, {'id': 1, 'ner_tags': [2, 1, 3, 0, 0, 0], 'tokens': ['zoom', 'client', '3.5.22132.0730', 'for', 'mac', 'os.']}, {'id': 2, 'ner_tags': [2, 1, 4, 4, 4, 3, 0, 0, 0, 0], 'tokens': ['yithemes', 'yith', 'woocommerce', 'product', 'add-ons', '1.3.2', 'premium', 'edition', 'for', 'wordpress.']}]\n"
     ]
    }
   ],
   "source": [
    "# Create NER Data Object\n",
    "dm_test = NERDataMaker(test_text)\n",
    "if (verbose):\n",
    "    print(\"TEST NER DATA OBJECTS\")\n",
    "    print(f\"  - total examples = {len(dm_test)}\")\n",
    "    print(f\"  - labels = {dm_test.id2label}\")\n",
    "    print(f\"  - Examples = {dm_test[0:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATE NER DATA OBJECTS\n",
      "  - total examples = 500\n",
      "  - labels = {0: 'O', 1: 'B-product', 2: 'B-vendor', 3: 'B-version', 4: 'I-product', 5: 'I-vendor'}\n",
      "  - Examples = [{'id': 0, 'ner_tags': [2, 1, 4, 3, 0, 0], 'tokens': ['10web', 'form', 'maker', '1.8.0', 'for', 'wordpress.']}, {'id': 1, 'ner_tags': [2, 1, 3], 'tokens': ['puppet', 'facter', '1.6.0']}, {'id': 2, 'ner_tags': [2, 1, 3], 'tokens': ['cisco', 'ios', '3.13.8s']}]\n"
     ]
    }
   ],
   "source": [
    "# Create NER Data Object\n",
    "dm_validate = NERDataMaker(validate_text)\n",
    "if (verbose):\n",
    "    print(\"VALIDATE NER DATA OBJECTS\")\n",
    "    print(f\"  - total examples = {len(dm_validate)}\")\n",
    "    print(f\"  - labels = {dm_validate.id2label}\")\n",
    "    print(f\"  - Examples = {dm_validate[0:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELS SUMMARY:\n",
      "  - Train labels = {0: 'O', 1: 'B-product', 2: 'B-vendor', 3: 'B-version', 4: 'I-product', 5: 'I-vendor'}\n",
      "  - Test labels = {0: 'O', 1: 'B-product', 2: 'B-vendor', 3: 'B-version', 4: 'I-product', 5: 'I-vendor'}\n",
      "  - Validation labels = {0: 'O', 1: 'B-product', 2: 'B-vendor', 3: 'B-version', 4: 'I-product', 5: 'I-vendor'}\n"
     ]
    }
   ],
   "source": [
    "if (verbose):\n",
    "    print(\"LABELS SUMMARY:\")\n",
    "    print(f\"  - Train labels = {dm.id2label}\")\n",
    "    print(f\"  - Test labels = {dm_test.id2label}\")\n",
    "    print(f\"  - Validation labels = {dm_validate.id2label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER model\n",
    "For this demo, I’ll use distilbert-base-uncased model. The dm object contains few properties which we pass to the AutoModelForTokenClassification.from_pretrained method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_token_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6867f3509c24279ac993ffafcdd8084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be2d10f0087496b99037b8de912597a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf5b34c24934eafb6cf192765279ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = dm.as_hf_dataset(tokenizer=tokenizer)\n",
    "test_ds = dm_test.as_hf_dataset(tokenizer=tokenizer)\n",
    "validate_ds = dm_validate.as_hf_dataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(pretrained_model_name, num_labels=len(dm.unique_entities), id2label=dm.id2label, label2id=dm.label2id, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DEVEL\\software\\miniconda3\\envs\\cpegen\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/results\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    logging_first_step=True,\n",
    "    # save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=train_logging_steps,\n",
    "    learning_rate=train_learning_rate,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=num_decay,\n",
    "    seed = p_seed,\n",
    "    data_seed = p_seed,\n",
    "    load_best_model_at_end = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds, \n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=train_patience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "ProgressCallback\n",
      "EarlyStoppingCallback\n",
      "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "ProgressCallback\n",
      "EarlyStoppingCallback\n",
      "TensorBoardCallback\n"
     ]
    }
   ],
   "source": [
    "trainer.add_callback(TensorBoardCallback())\n",
    "tensorboard_sm = SummaryWriter(log_dir=training_args.logging_dir)\n",
    "tensorboard_cb = TensorBoardCallback(tensorboard_sm)\n",
    "trainer.add_callback(tensorboard_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-product\",\n",
      "    \"2\": \"B-vendor\",\n",
      "    \"3\": \"B-version\",\n",
      "    \"4\": \"I-product\",\n",
      "    \"5\": \"I-vendor\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"B-product\": 1,\n",
      "    \"B-vendor\": 2,\n",
      "    \"B-version\": 3,\n",
      "    \"I-product\": 4,\n",
      "    \"I-vendor\": 5,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (verbose):\n",
    "    print(trainer.model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train custom NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47dc38018724e6f8e2e2fbe27791228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7779, 'grad_norm': 2.7479095458984375, 'learning_rate': 1.999493670886076e-05, 'epoch': 0.01}\n",
      "{'loss': 0.455, 'grad_norm': 4.575979709625244, 'learning_rate': 1.949367088607595e-05, 'epoch': 1.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b643813cd044eaba856142d4d329fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07624180614948273, 'eval_runtime': 1.0871, 'eval_samples_per_second': 1839.802, 'eval_steps_per_second': 57.954, 'epoch': 1.27}\n",
      "{'loss': 0.0581, 'grad_norm': 2.669964075088501, 'learning_rate': 1.89873417721519e-05, 'epoch': 2.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7541e4ec070470ab2aabf4ddda307d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.042824890464544296, 'eval_runtime': 1.1249, 'eval_samples_per_second': 1777.927, 'eval_steps_per_second': 56.005, 'epoch': 2.53}\n",
      "{'loss': 0.0228, 'grad_norm': 1.590532660484314, 'learning_rate': 1.848101265822785e-05, 'epoch': 3.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608201fdbf074bb698342a82cf4510ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.034996047616004944, 'eval_runtime': 1.1098, 'eval_samples_per_second': 1802.103, 'eval_steps_per_second': 56.766, 'epoch': 3.8}\n",
      "{'loss': 0.0128, 'grad_norm': 0.0630422905087471, 'learning_rate': 1.7974683544303798e-05, 'epoch': 5.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f0feca94f4450984eb038740687f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.031973451375961304, 'eval_runtime': 1.0956, 'eval_samples_per_second': 1825.558, 'eval_steps_per_second': 57.505, 'epoch': 5.06}\n",
      "{'loss': 0.0076, 'grad_norm': 0.17978914082050323, 'learning_rate': 1.746835443037975e-05, 'epoch': 6.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd36b1a345f4428bf0beafaffe30434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.032453179359436035, 'eval_runtime': 1.1301, 'eval_samples_per_second': 1769.765, 'eval_steps_per_second': 55.748, 'epoch': 6.33}\n",
      "{'loss': 0.0035, 'grad_norm': 0.45941653847694397, 'learning_rate': 1.6962025316455696e-05, 'epoch': 7.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40d851fd3714b41a40f7a7470083689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.028325360268354416, 'eval_runtime': 1.1299, 'eval_samples_per_second': 1770.031, 'eval_steps_per_second': 55.756, 'epoch': 7.59}\n",
      "{'loss': 0.0039, 'grad_norm': 0.027303170412778854, 'learning_rate': 1.6455696202531647e-05, 'epoch': 8.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb26e286c09490ab85425eae1efaf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03378201276063919, 'eval_runtime': 1.1229, 'eval_samples_per_second': 1781.059, 'eval_steps_per_second': 56.103, 'epoch': 8.86}\n",
      "{'loss': 0.0021, 'grad_norm': 0.007511452306061983, 'learning_rate': 1.5949367088607598e-05, 'epoch': 10.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2d06ff81df4908a10ea0be7efe1d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03360860049724579, 'eval_runtime': 1.1717, 'eval_samples_per_second': 1706.969, 'eval_steps_per_second': 53.77, 'epoch': 10.13}\n",
      "{'loss': 0.0012, 'grad_norm': 0.02606506645679474, 'learning_rate': 1.5443037974683546e-05, 'epoch': 11.39}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a53ea9907445488ae9e5f6adaccdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.040890250355005264, 'eval_runtime': 1.1782, 'eval_samples_per_second': 1697.497, 'eval_steps_per_second': 53.471, 'epoch': 11.39}\n",
      "{'loss': 0.0022, 'grad_norm': 0.013241028413176537, 'learning_rate': 1.4936708860759495e-05, 'epoch': 12.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63fa78b9a804a06a7208a80d37cb2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03999369591474533, 'eval_runtime': 1.1422, 'eval_samples_per_second': 1751.018, 'eval_steps_per_second': 55.157, 'epoch': 12.66}\n",
      "{'loss': 0.0028, 'grad_norm': 0.010196661576628685, 'learning_rate': 1.4430379746835444e-05, 'epoch': 13.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a5c26f835f48b08d7202b939dbec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.038010671734809875, 'eval_runtime': 1.1745, 'eval_samples_per_second': 1702.913, 'eval_steps_per_second': 53.642, 'epoch': 13.92}\n",
      "{'train_runtime': 98.2152, 'train_samples_per_second': 1272.716, 'train_steps_per_second': 40.218, 'train_loss': 0.053190448731184004, 'epoch': 13.92}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/db_cpener_vpv/tokenizer\\\\tokenizer_config.json',\n",
       " '../models/db_cpener_vpv/tokenizer\\\\special_tokens_map.json',\n",
       " '../models/db_cpener_vpv/tokenizer\\\\vocab.txt',\n",
       " '../models/db_cpener_vpv/tokenizer\\\\added_tokens.json',\n",
       " '../models/db_cpener_vpv/tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained(save_model_name)\n",
    "tokenizer.save_pretrained(save_model_name + \"/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define inference pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"max\", device=0) # pass device=0 if using gpu\n",
    "\n",
    "def predict_cpe_ner(df, col_name):\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    out_ner = []\n",
    "    for out in pipe(KeyDataset(dataset, col_name), batch_size=8):\n",
    "        i = process_ner_out(out, p_ner_vendor, p_ner_product, p_ner_version)\n",
    "        out_ner.append(i)\n",
    "\n",
    "    df_predict = pd.DataFrame.from_dict(out_ner)\n",
    "    \n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>cpe</th>\n",
       "      <th>vendor</th>\n",
       "      <th>product</th>\n",
       "      <th>version</th>\n",
       "      <th>annotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>15069</td>\n",
       "      <td>10web form maker 1.8.0 for wordpress</td>\n",
       "      <td>cpe:2.3:a:10web:form_maker:1.8.0:*:*:*:*:wordp...</td>\n",
       "      <td>10web</td>\n",
       "      <td>form maker</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>[10web](vendor) [form maker](product) [1.8.0](...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>4616</td>\n",
       "      <td>puppet facter 1.6.0</td>\n",
       "      <td>cpe:2.3:a:puppet:facter:1.6.0:-:*:*:*:*:*:*</td>\n",
       "      <td>puppet</td>\n",
       "      <td>facter</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>[puppet](vendor) [facter](product) [1.6.0](ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>10357</td>\n",
       "      <td>cisco ios 3.13.8s</td>\n",
       "      <td>cpe:2.3:o:cisco:ios:3.13.8s:*:*:*:*:*:*:*</td>\n",
       "      <td>cisco</td>\n",
       "      <td>ios</td>\n",
       "      <td>3.13.8s</td>\n",
       "      <td>[cisco](vendor) [ios](product) [3.13.8s](versi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>14209</td>\n",
       "      <td>jenkins slack 2.35 for jenkins</td>\n",
       "      <td>cpe:2.3:a:jenkins:slack:2.35:*:*:*:*:jenkins:*:*</td>\n",
       "      <td>jenkins</td>\n",
       "      <td>slack</td>\n",
       "      <td>2.35</td>\n",
       "      <td>[jenkins](vendor) [slack](product) [2.35](vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>2092</td>\n",
       "      <td>plustime service area postcode checker 2.0.2 f...</td>\n",
       "      <td>cpe:2.3:a:plustime:service_area_postcode_check...</td>\n",
       "      <td>plustime</td>\n",
       "      <td>service area postcode checker</td>\n",
       "      <td>2.0.2</td>\n",
       "      <td>[plustime](vendor) [service area postcode chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>17396</td>\n",
       "      <td>ruby-lang ruby 1.8.6.355</td>\n",
       "      <td>cpe:2.3:a:ruby-lang:ruby:1.8.6.355:*:*:*:*:*:*:*</td>\n",
       "      <td>ruby-lang</td>\n",
       "      <td>ruby</td>\n",
       "      <td>1.8.6.355</td>\n",
       "      <td>[ruby-lang](vendor) [ruby](product) [1.8.6.355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>13452</td>\n",
       "      <td>primetek primefaces 3.5.1</td>\n",
       "      <td>cpe:2.3:a:primetek:primefaces:3.5.1:*:*:*:*:*:*:*</td>\n",
       "      <td>primetek</td>\n",
       "      <td>primefaces</td>\n",
       "      <td>3.5.1</td>\n",
       "      <td>[primetek](vendor) [primefaces](product) [3.5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>10966</td>\n",
       "      <td>ec-cube e-mail newsletter management (mail-mag...</td>\n",
       "      <td>cpe:2.3:a:ec-cube:e-mail_newsletter_management...</td>\n",
       "      <td>ec-cube</td>\n",
       "      <td>e-mail newsletter management</td>\n",
       "      <td>4.0.0</td>\n",
       "      <td>[ec-cube](vendor) [e-mail newsletter managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>12580</td>\n",
       "      <td>authzed spicedb 1.5.0</td>\n",
       "      <td>cpe:2.3:a:authzed:spicedb:1.5.0:*:*:*:*:*:*:*</td>\n",
       "      <td>authzed</td>\n",
       "      <td>spicedb</td>\n",
       "      <td>1.5.0</td>\n",
       "      <td>[authzed](vendor) [spicedb](product) [1.5.0](v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>3476</td>\n",
       "      <td>serverscheck monitoring software 7.11.0</td>\n",
       "      <td>cpe:2.3:a:serverscheck:monitoring_software:7.1...</td>\n",
       "      <td>serverscheck</td>\n",
       "      <td>monitoring software</td>\n",
       "      <td>7.11.0</td>\n",
       "      <td>[serverscheck](vendor) [monitoring software](p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              title  \\\n",
       "1511  15069               10web form maker 1.8.0 for wordpress   \n",
       "1882   4616                                puppet facter 1.6.0   \n",
       "651   10357                                  cisco ios 3.13.8s   \n",
       "4930  14209                     jenkins slack 2.35 for jenkins   \n",
       "3089   2092  plustime service area postcode checker 2.0.2 f...   \n",
       "...     ...                                                ...   \n",
       "1987  17396                           ruby-lang ruby 1.8.6.355   \n",
       "3648  13452                          primetek primefaces 3.5.1   \n",
       "344   10966  ec-cube e-mail newsletter management (mail-mag...   \n",
       "4482  12580                              authzed spicedb 1.5.0   \n",
       "986    3476            serverscheck monitoring software 7.11.0   \n",
       "\n",
       "                                                    cpe        vendor  \\\n",
       "1511  cpe:2.3:a:10web:form_maker:1.8.0:*:*:*:*:wordp...         10web   \n",
       "1882        cpe:2.3:a:puppet:facter:1.6.0:-:*:*:*:*:*:*        puppet   \n",
       "651           cpe:2.3:o:cisco:ios:3.13.8s:*:*:*:*:*:*:*         cisco   \n",
       "4930   cpe:2.3:a:jenkins:slack:2.35:*:*:*:*:jenkins:*:*       jenkins   \n",
       "3089  cpe:2.3:a:plustime:service_area_postcode_check...      plustime   \n",
       "...                                                 ...           ...   \n",
       "1987   cpe:2.3:a:ruby-lang:ruby:1.8.6.355:*:*:*:*:*:*:*     ruby-lang   \n",
       "3648  cpe:2.3:a:primetek:primefaces:3.5.1:*:*:*:*:*:*:*      primetek   \n",
       "344   cpe:2.3:a:ec-cube:e-mail_newsletter_management...       ec-cube   \n",
       "4482      cpe:2.3:a:authzed:spicedb:1.5.0:*:*:*:*:*:*:*       authzed   \n",
       "986   cpe:2.3:a:serverscheck:monitoring_software:7.1...  serverscheck   \n",
       "\n",
       "                            product    version  \\\n",
       "1511                     form maker      1.8.0   \n",
       "1882                         facter      1.6.0   \n",
       "651                             ios    3.13.8s   \n",
       "4930                          slack       2.35   \n",
       "3089  service area postcode checker      2.0.2   \n",
       "...                             ...        ...   \n",
       "1987                           ruby  1.8.6.355   \n",
       "3648                     primefaces      3.5.1   \n",
       "344    e-mail newsletter management      4.0.0   \n",
       "4482                        spicedb      1.5.0   \n",
       "986             monitoring software     7.11.0   \n",
       "\n",
       "                                              annotated  \n",
       "1511  [10web](vendor) [form maker](product) [1.8.0](...  \n",
       "1882  [puppet](vendor) [facter](product) [1.6.0](ver...  \n",
       "651   [cisco](vendor) [ios](product) [3.13.8s](versi...  \n",
       "4930  [jenkins](vendor) [slack](product) [2.35](vers...  \n",
       "3089  [plustime](vendor) [service area postcode chec...  \n",
       "...                                                 ...  \n",
       "1987  [ruby-lang](vendor) [ruby](product) [1.8.6.355...  \n",
       "3648  [primetek](vendor) [primefaces](product) [3.5....  \n",
       "344   [ec-cube](vendor) [e-mail newsletter managemen...  \n",
       "4482  [authzed](vendor) [spicedb](product) [1.5.0](v...  \n",
       "986   [serverscheck](vendor) [monitoring software](p...  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (verbose):\n",
    "    display(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict entities using custom NER model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_vendor</th>\n",
       "      <th>scr_vendor</th>\n",
       "      <th>ner_product</th>\n",
       "      <th>scr_product</th>\n",
       "      <th>ner_version</th>\n",
       "      <th>scr_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10web</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>form maker</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.999176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>puppet</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>facter</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.998727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cisco</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>ios</td>\n",
       "      <td>0.998604</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.998650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jenkins</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>slack</td>\n",
       "      <td>0.998702</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plustime</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>service area postcode checker</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ruby</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>ruby</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>1.8.6</td>\n",
       "      <td>0.998653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>primetek</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>primefaces</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.999060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ec</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>cube e-mail newsletter management</td>\n",
       "      <td>0.798827</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.998036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>authzed</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>spicedb</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.999118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>serverscheck</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>monitoring software</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>7.11</td>\n",
       "      <td>0.999171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ner_vendor  scr_vendor                        ner_product  scr_product  \\\n",
       "0           10web    0.999512                         form maker     0.999332   \n",
       "1          puppet    0.999438                             facter     0.998790   \n",
       "2           cisco    0.999426                                ios     0.998604   \n",
       "3         jenkins    0.999454                              slack     0.998702   \n",
       "4        plustime    0.999438      service area postcode checker     0.998452   \n",
       "..            ...         ...                                ...          ...   \n",
       "495          ruby    0.999517                               ruby     0.999271   \n",
       "496      primetek    0.999457                         primefaces     0.999497   \n",
       "497            ec    0.999347  cube e-mail newsletter management     0.798827   \n",
       "498       authzed    0.999361                            spicedb     0.999526   \n",
       "499  serverscheck    0.999561                monitoring software     0.999131   \n",
       "\n",
       "    ner_version  scr_version  \n",
       "0           1.8     0.999176  \n",
       "1           1.6     0.998727  \n",
       "2          3.13     0.998650  \n",
       "3             2     0.998271  \n",
       "4           2.0     0.999105  \n",
       "..          ...          ...  \n",
       "495       1.8.6     0.998653  \n",
       "496         3.5     0.999060  \n",
       "497         4.0     0.998036  \n",
       "498         1.5     0.999118  \n",
       "499        7.11     0.999171  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_predict = predict_cpe_ner(validate, \"title\")\n",
    "if (verbose):\n",
    "    display(df_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply hack for version entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>vendor</th>\n",
       "      <th>product</th>\n",
       "      <th>version</th>\n",
       "      <th>ner_vendor</th>\n",
       "      <th>scr_vendor</th>\n",
       "      <th>ner_product</th>\n",
       "      <th>scr_product</th>\n",
       "      <th>ner_version</th>\n",
       "      <th>scr_version</th>\n",
       "      <th>ner_version_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15069</td>\n",
       "      <td>10web form maker 1.8.0 for wordpress</td>\n",
       "      <td>10web</td>\n",
       "      <td>form maker</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>10web</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>form maker</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>1.8.0</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4616</td>\n",
       "      <td>puppet facter 1.6.0</td>\n",
       "      <td>puppet</td>\n",
       "      <td>facter</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>puppet</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>facter</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10357</td>\n",
       "      <td>cisco ios 3.13.8s</td>\n",
       "      <td>cisco</td>\n",
       "      <td>ios</td>\n",
       "      <td>3.13.8s</td>\n",
       "      <td>cisco</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>ios</td>\n",
       "      <td>0.998604</td>\n",
       "      <td>3.13.8s</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14209</td>\n",
       "      <td>jenkins slack 2.35 for jenkins</td>\n",
       "      <td>jenkins</td>\n",
       "      <td>slack</td>\n",
       "      <td>2.35</td>\n",
       "      <td>jenkins</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>slack</td>\n",
       "      <td>0.998702</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2092</td>\n",
       "      <td>plustime service area postcode checker 2.0.2 f...</td>\n",
       "      <td>plustime</td>\n",
       "      <td>service area postcode checker</td>\n",
       "      <td>2.0.2</td>\n",
       "      <td>plustime</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>service area postcode checker</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>2.0.2</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>17396</td>\n",
       "      <td>ruby-lang ruby 1.8.6.355</td>\n",
       "      <td>ruby-lang</td>\n",
       "      <td>ruby</td>\n",
       "      <td>1.8.6.355</td>\n",
       "      <td>ruby</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>ruby</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>1.8.6.355</td>\n",
       "      <td>0.998653</td>\n",
       "      <td>1.8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>13452</td>\n",
       "      <td>primetek primefaces 3.5.1</td>\n",
       "      <td>primetek</td>\n",
       "      <td>primefaces</td>\n",
       "      <td>3.5.1</td>\n",
       "      <td>primetek</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>primefaces</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>3.5.1</td>\n",
       "      <td>0.999060</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>10966</td>\n",
       "      <td>ec-cube e-mail newsletter management (mail-mag...</td>\n",
       "      <td>ec-cube</td>\n",
       "      <td>e-mail newsletter management</td>\n",
       "      <td>4.0.0</td>\n",
       "      <td>ec</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>cube e-mail newsletter management</td>\n",
       "      <td>0.798827</td>\n",
       "      <td>4.0.0</td>\n",
       "      <td>0.998036</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>12580</td>\n",
       "      <td>authzed spicedb 1.5.0</td>\n",
       "      <td>authzed</td>\n",
       "      <td>spicedb</td>\n",
       "      <td>1.5.0</td>\n",
       "      <td>authzed</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>spicedb</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>1.5.0</td>\n",
       "      <td>0.999118</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>3476</td>\n",
       "      <td>serverscheck monitoring software 7.11.0</td>\n",
       "      <td>serverscheck</td>\n",
       "      <td>monitoring software</td>\n",
       "      <td>7.11.0</td>\n",
       "      <td>serverscheck</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>monitoring software</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>7.11.0</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                              title        vendor  \\\n",
       "0    15069               10web form maker 1.8.0 for wordpress         10web   \n",
       "1     4616                                puppet facter 1.6.0        puppet   \n",
       "2    10357                                  cisco ios 3.13.8s         cisco   \n",
       "3    14209                     jenkins slack 2.35 for jenkins       jenkins   \n",
       "4     2092  plustime service area postcode checker 2.0.2 f...      plustime   \n",
       "..     ...                                                ...           ...   \n",
       "495  17396                           ruby-lang ruby 1.8.6.355     ruby-lang   \n",
       "496  13452                          primetek primefaces 3.5.1      primetek   \n",
       "497  10966  ec-cube e-mail newsletter management (mail-mag...       ec-cube   \n",
       "498  12580                              authzed spicedb 1.5.0       authzed   \n",
       "499   3476            serverscheck monitoring software 7.11.0  serverscheck   \n",
       "\n",
       "                           product    version    ner_vendor  scr_vendor  \\\n",
       "0                       form maker      1.8.0         10web    0.999512   \n",
       "1                           facter      1.6.0        puppet    0.999438   \n",
       "2                              ios    3.13.8s         cisco    0.999426   \n",
       "3                            slack       2.35       jenkins    0.999454   \n",
       "4    service area postcode checker      2.0.2      plustime    0.999438   \n",
       "..                             ...        ...           ...         ...   \n",
       "495                           ruby  1.8.6.355          ruby    0.999517   \n",
       "496                     primefaces      3.5.1      primetek    0.999457   \n",
       "497   e-mail newsletter management      4.0.0            ec    0.999347   \n",
       "498                        spicedb      1.5.0       authzed    0.999361   \n",
       "499            monitoring software     7.11.0  serverscheck    0.999561   \n",
       "\n",
       "                           ner_product  scr_product ner_version  scr_version  \\\n",
       "0                           form maker     0.999332       1.8.0     0.999176   \n",
       "1                               facter     0.998790       1.6.0     0.998727   \n",
       "2                                  ios     0.998604     3.13.8s     0.998650   \n",
       "3                                slack     0.998702        2.35     0.998271   \n",
       "4        service area postcode checker     0.998452       2.0.2     0.999105   \n",
       "..                                 ...          ...         ...          ...   \n",
       "495                               ruby     0.999271   1.8.6.355     0.998653   \n",
       "496                         primefaces     0.999497       3.5.1     0.999060   \n",
       "497  cube e-mail newsletter management     0.798827       4.0.0     0.998036   \n",
       "498                            spicedb     0.999526       1.5.0     0.999118   \n",
       "499                monitoring software     0.999131      7.11.0     0.999171   \n",
       "\n",
       "    ner_version_raw  \n",
       "0               1.8  \n",
       "1               1.6  \n",
       "2              3.13  \n",
       "3                 2  \n",
       "4               2.0  \n",
       "..              ...  \n",
       "495           1.8.6  \n",
       "496             3.5  \n",
       "497             4.0  \n",
       "498             1.5  \n",
       "499            7.11  \n",
       "\n",
       "[500 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_result = pd.concat([validate.loc[:,[i for i in validate.columns if not (i.startswith('annotated') or i.startswith('cpe'))]].reset_index(drop=True), df_predict], axis=1)\n",
    "if (\"ner_version\" in df_result.columns):\n",
    "    df_result['ner_version_raw'] = df_result['ner_version']\n",
    "    df_result['ner_version'] = df_result.apply(hackvers, axis=1)\n",
    "if (verbose):\n",
    "    display(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
